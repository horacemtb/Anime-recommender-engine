{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, ParameterGrid\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import mlflow\n",
    "import boto3\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://84.201.153.30:8000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/dmitry-ds/postgresql-credentials/creds.json', 'r') as f:\n",
    "    creds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "s3 = session.client(service_name = 's3', endpoint_url = 'https://storage.yandexcloud.net', region_name = 'ru-central1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(f\"\"\"host=c-c9qm2f2d6d1lkiqst4qn.rw.mdb.yandexcloud.net\n",
    "port=6432\n",
    "sslmode=disable\n",
    "dbname=anime-rec-sys-db\n",
    "user={creds['user']}\n",
    "password={creds['password']}\n",
    "target_session_attrs=read-write\n",
    "                        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_user_ids(s3):\n",
    "    \n",
    "    get_object_response = s3.get_object(Bucket = 'anime-rec-sys-data', Key = 'user_id_test.npy')\n",
    "    user_id_test = np.load(io.BytesIO(get_object_response['Body'].read()))\n",
    "    \n",
    "    return user_id_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_data(s3):\n",
    "    \n",
    "    get_object_response = s3.get_object(Bucket = 'anime-rec-sys-data', Key = 'anime_selected.csv')\n",
    "    anime_selected = pd.read_csv(io.BytesIO(get_object_response['Body'].read()))\n",
    "    \n",
    "    get_object_response = s3.get_object(Bucket = 'anime-rec-sys-data', Key = 'anime_synopsis_emb_2.csv')\n",
    "    anime_synopsis_emb = pd.read_csv(io.BytesIO(get_object_response['Body'].read()))\n",
    "    \n",
    "    get_object_response = s3.get_object(Bucket = 'anime-rec-sys-data', Key = 'lightfm_emb_df_50e.csv')\n",
    "    lightfm_emb_df = pd.read_csv(io.BytesIO(get_object_response['Body'].read()))\n",
    "    \n",
    "    return anime_selected, anime_synopsis_emb, lightfm_emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_data(connection):\n",
    "    \n",
    "    sql_query = pd.read_sql_query(\"SELECT * FROM selectedratings;\", connection)\n",
    "    rating_selected = pd.DataFrame(sql_query, columns = ['user_id', 'anime_id', 'rating'])\n",
    "    \n",
    "    sql_query = pd.read_sql_query(\"SELECT * FROM userpreferences;\", connection)\n",
    "    users = pd.DataFrame(sql_query)\n",
    "    users.columns = ['user_id', 'Action', 'Adventure', 'Cars', 'Comedy', 'Dementia',\n",
    "                     'Demons', 'Drama', 'Ecchi', 'Fantasy', 'Game', 'Harem', 'Hentai',\n",
    "                     'Historical', 'Horror', 'Josei', 'Kids', 'Magic', 'Martial Arts',\n",
    "                     'Mecha', 'Military', 'Music', 'Mystery', 'Parody', 'Police',\n",
    "                     'Psychological', 'Romance', 'Samurai', 'School', 'Sci-Fi', 'Seinen',\n",
    "                     'Shoujo', 'Shoujo Ai', 'Shounen', 'Shounen Ai', 'Slice of Life',\n",
    "                     'Space', 'Sports', 'Super Power', 'Supernatural', 'Thriller', 'Unknown',\n",
    "                     'Vampire', 'Yaoi', 'Yuri', 'mean_rating']\n",
    "    \n",
    "    connection.close()\n",
    "    \n",
    "    return rating_selected, users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lightgbm_dataset(rating_selected, users, lightfm_emb_df, anime_synopsis_emb):\n",
    "    \n",
    "    lgb_dataset = rating_selected.copy()\n",
    "    lgb_dataset = lgb_dataset.merge(users[users.columns], on = 'user_id', how = 'left')\n",
    "    lgb_dataset = lgb_dataset.merge(lightfm_emb_df[lightfm_emb_df.columns], on = 'anime_id', how = 'left')\n",
    "    lgb_dataset = lgb_dataset.merge(anime_synopsis_emb[anime_synopsis_emb.columns], on = 'anime_id', how = 'left')\n",
    "    \n",
    "    return lgb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_selected, anime_synopsis_emb, lightfm_emb_df = get_item_data(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_selected, users = get_user_data(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_dataset = create_lightgbm_dataset(rating_selected, users, lightfm_emb_df, anime_synopsis_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_test = test_user_ids(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_train = lgb_dataset['user_id'].unique()[~np.isin(lgb_dataset['user_id'].unique(), user_id_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_train, user_id_val = train_test_split(user_id_train, test_size = 0.15, random_state = 586) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Num train {len(user_id_train)}')\n",
    "print(f'Num val {len(user_id_val)}')\n",
    "print(f'Num test {len(user_id_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lgb_dataset[lgb_dataset['user_id'].isin(user_id_train)]\n",
    "val = lgb_dataset[lgb_dataset['user_id'].isin(user_id_val)]\n",
    "test = lgb_dataset[lgb_dataset['user_id'].isin(user_id_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train.iloc[:, 3:], train['rating'])\n",
    "lgb_val = lgb.Dataset(val.iloc[:, 3:], val['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'objective': 'regression',\n",
    "#           'max_depth': 8,\n",
    "#           'n_estimators': 2000,\n",
    "#           'num_leaves': 2**8-1,\n",
    "#           'learning_rate': 0.01,\n",
    "#           'colsample_bytree': 0.8,\n",
    "#           'subsample': 0.8,\n",
    "#           'early_stopping_rounds': 20,\n",
    "#           'random_state': 42,\n",
    "#           'n_jobs': 8\n",
    "#          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/dmitry-ds/rec-sys/Anime-recommender-engine/app/models/LightGBM-v5.pickle', 'wb') as file:\n",
    "#     pickle.dump(lgbm_regressor, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_regressor = lgb.train(params,\n",
    "#                            lgb_train,\n",
    "#                            valid_sets = lgb_val,\n",
    "#                            verbose_eval = 10\n",
    "#                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/dmitry-ds/rec-sys/Anime-recommender-engine/app/models/LightGBM-v5.pickle', 'rb') as file:\n",
    "    lgbm_regressor = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = lgbm_regressor.predict(test.iloc[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_absolute_error(test['rating'], test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.lightgbm.log_model(lgbm_regressor, 'LightGBM-regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = median_absolute_error(test['rating'], test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlflow.log_metric('test MAE', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores = pd.DataFrame(data = {'test MAE': 0.0}, index=range(bootstrap_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predicted_rating'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_model_results_df = test[['rating', 'predicted_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(bootstrap_iterations):\n",
    "    prod_sample = prod_model_results_df.sample(frac=1.0, replace=True)\n",
    "    prod_scores.loc[i, 'test MAE'] = median_absolute_error(prod_sample['rating'], prod_sample['predicted_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_score_mean = prod_scores['test MAE'].mean()\n",
    "prod_score_std = prod_scores['test MAE'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric('boostrap MAE', prod_score_mean)\n",
    "mlflow.log_metric('boostrap std', prod_score_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv('users.csv', index = False)\n",
    "rating_selected.to_csv('rating_selected.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_artifact('users.csv')\n",
    "mlflow.log_artifact('rating_selected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('users.csv')\n",
    "os.remove('rating_selected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_run = mlflow.search_runs().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LightGBM-ratings_predictor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model_version = mlflow.register_model(f'runs:/{mlflow_run.run_id}/LightGBM-regressor', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "  name = model_name,\n",
    "  version = new_model_version.version,\n",
    "  stage = \"Production\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prod_model(model_name):\n",
    "    prod_model = mlflow.lightgbm.load_model(f'models:/{model_name}/Production')\n",
    "    return prod_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_model = get_prod_model(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
